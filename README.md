# ðŸ§  Sentiment Analysis using DistilBERT (SST-2 Fine-Tuned)
_____________________________________________________________

This project demonstrates how to use the Hugging Face ðŸ¤— Transformers library with the model [`distilbert/distilbert-base-uncased-finetuned-sst-2-english`](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english) for sentiment analysis. The model is a lightweight version of BERT, fine-tuned on the Stanford Sentiment Treebank v2 (SST-2) for binary sentiment classification (positive or negative).

---

## ðŸ“Œ Table of Contents
_________________________

- [Overview](#overview)
- [Installation](#installation)
- [Quickstart](#quickstart)
- [Example Usage](#example-usage)
- [API](#api)
- [Performance](#performance)
- [License](#license)
- [Acknowledgements](#acknowledgements)

---

## ðŸ“ Overview
____________________

The SST-2 dataset is widely used for training sentiment classifiers. This project allows you to:

- Classify input text into **positive** or **negative** sentiment.
- Use the DistilBERT transformer model for faster inference.
- Integrate easily with web apps, notebooks, or production systems.

---

## âš™ï¸ Working
______________________
>First get the dataset from HuggingFace and Transform the data using Transform

>Now download all the required libraries

>The Transformed dataset is used to Classify the text and analyse the sentiment

>Use Gradio for User-interface

>Use matplotlib to plot the data and ensure the data set is ploted on to the graph


